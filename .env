const { spawn } = require('child_process');
const ffmpegPath = require('ffmpeg-static');
const ffmpeg = require('fluent-ffmpeg');

const inputPath = 'input.mp4';
const outputPath = 'output.mp4';

const command = ffmpeg(inputPath)
  .format('mp4')
  .videoCodec('libx264')
  .audioCodec('aac')
  .on('error', function (err) {
    console.log('An error occurred: ' + err.message);
  })
  .on('end', function () {
    console.log('Conversion complete!');
  })
  .pipe();

const args = ['-y', '-i', '-', '-preset', 'slow', '-crf', '22', outputPath];

const ffmpegProcess = spawn(ffmpegPath, args);

command.pipe(ffmpegProcess.stdin);
ffmpegProcess.stdout.pipe(process.stdout);
ffmpegProcess.stderr.pipe(process.stderr);















Sure, here's an example Node.js code using the ws and fluent-ffmpeg libraries to pass video streams from a WebSocket as input in fluent-ffmpeg:

js
Copy code
const WebSocket = require('ws');
const ffmpeg = require('fluent-ffmpeg');

// Create a WebSocket server
const wss = new WebSocket.Server({ port: 8080 });

// Start ffmpeg with the WebSocket stream as input
const command = ffmpeg();
command.inputFormat('mpegts');
command.inputOptions('-re');
command.input('pipe:0');
command.output('output.mp4');
command.run();

// Listen for WebSocket connections
wss.on('connection', function connection(ws) {
  console.log('WebSocket connected');

  // When data is received on the WebSocket, write it to the ffmpeg input stream
  ws.on('message', function incoming(data) {
    command.stdin.write(data);
  });

  // When the WebSocket is closed, end the ffmpeg input stream
  ws.on('close', function() {
    command.stdin.end();
  });
});














import React, { useRef, useEffect } from 'react';

function App() {
  const videoRef = useRef(null);
  const socketRef = useRef(null);

  useEffect(() => {
    // Connect to the WebSocket server
    socketRef.current = new WebSocket('ws://your-websocket-server-url');

    // When the WebSocket connection is open, start sending video frames
    socketRef.current.addEventListener('open', () => {
      // Start the camera stream
      navigator.mediaDevices.getUserMedia({ video: true })
        .then(stream => {
          videoRef.current.srcObject = stream;
          videoRef.current.play();

          // Send video frames to the WebSocket server every 100 milliseconds
          setInterval(() => {
            // Get the current video frame as an ImageBitmap
            const imageBitmap = videoRef.current.videoWidth && videoRef.current.videoHeight && createImageBitmap(videoRef.current);

            if (imageBitmap) {
              // Convert the ImageBitmap to a Blob
              imageBitmap.blob()
                .then(blob => {
                  // Send the Blob to the WebSocket server
                  socketRef.current.send(blob);
                })
                .catch(error => {
                  console.error('Error converting ImageBitmap to Blob:', error);
                });
            }
          }, 100);
        })
        .catch(error => {
          console.error('Error accessing camera:', error);
        });
    });

    // Clean up the WebSocket connection when the component unmounts
    return () => {
      socketRef.current && socketRef.current.close();
    };
  }, []);

  return (
    <video ref={videoRef} width={640} height={480} />
  );
}

export default App;


















import React, { useRef, useEffect } from 'react';

function App() {
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const socketRef = useRef(null);

  useEffect(() => {
    // Connect to the WebSocket server
    socketRef.current = new WebSocket('ws://your-websocket-server-url');

    // When the WebSocket connection is open, start sending video frames
    socketRef.current.addEventListener('open', () => {
      // Start the camera stream
      navigator.mediaDevices.getUserMedia({ video: true })
        .then(stream => {
          videoRef.current.srcObject = stream;
          videoRef.current.play();

          // Send video frames to the WebSocket server every 100 milliseconds
          setInterval(() => {
            // Get the current video frame as an ImageData object
            const context = canvasRef.current.getContext('2d');
            context.drawImage(videoRef.current, 0, 0, canvasRef.current.width, canvasRef.current.height);
            const imageData = context.getImageData(0, 0, canvasRef.current.width, canvasRef.current.height);

            // Convert the ImageData object to a Blob
            const blob = new Blob([imageData.data.buffer], { type: 'image/jpeg' });

            // Send the Blob to the WebSocket server
            socketRef.current.send(blob);
          }, 100);
        })
        .catch(error => {
          console.error('Error accessing camera:', error);
        });
    });

    // Clean up the WebSocket connection when the component unmounts
    return () => {
      socketRef.current && socketRef.current.close();
    };
  }, []);

  return (
    <div>
      <video ref={videoRef} width={640} height={480} />
      <canvas ref={canvasRef} style={{ display: 'none' }} width={640} height={480} />
    </div>
  );
}

export default App;









const child_process = require('child_process'); // To be used later for running FFmpeg
const express = require('express');
const ffmpeg = require('fluent-ffmpeg')
const http = require('http');
const { Readable } = require('stream');

const WebSocketServer = require('ws').Server;

const app = express();

const ffmpegPath = require('@ffmpeg-installer/ffmpeg').path;
const ffprobePath = require('@ffprobe-installer/ffprobe').path; 


ffmpeg.setFfmpegPath(ffmpegPath);
ffmpeg.setFfprobePath(ffprobePath);

const command = ffmpeg();



 const wss = new WebSocketServer({
    port:5001
  });

  const stream = new Readable();
  
  wss.on('connection', (ws, req) => {
    ws.on('message', (msg) => {


    console.log(msg,"from")
   
    msg.forEach(file =>{
      stream._read = () => {};
      stream.push(file);
      command = command.input(stream)
      
    })
     
  
   


    // stream.push(null);

   

 


    command.fps(1)
    .inputFormat('h264')
    .output('output.mp4')
    .on('end', () => console.log('Finished processing'))
    .run();
  





   }); 

      ws.send("I got you")

 



  
  });









 console.log(socket?.readyState,"first")
     socket.onopen=(event)=>{
       alert("Connected")
      //  socket.send("hey")

       setInterval(() => {
          console.log("cycle")
          const context = canvasRef.current.getContext('2d');
          console.log(context,"cxt")
          context.drawImage(videoEl.current, 0, 0, canvasRef.current.width, canvasRef.current.height);
          const imageData = context.getImageData(0, 0, canvasRef.current.width, canvasRef.current.height);
          console.log(imageData,"img")
          const blob = new Blob([imageData.data.buffer], { type: 'image/jpeg' });
           console.log(blob,"blob")

           if ( socket?.readyState === 3 ) {
            console.log("Websocket closed")
            socket.close()
            
            var newSocket =new WebSocket("ws://localhost:5001")
            sleep(30000)
            newSocket.send(blob);
           }else{
            console.log(socket.readyState,"else")
            socket.send(blob);
           }
         

       },100)

      }

    socket.onmessage=(event)=>{
      console.log(event.data)

    }